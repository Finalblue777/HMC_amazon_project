{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700b8c5d",
   "metadata": {},
   "source": [
    "# Explaining the Code\n",
    "\n",
    "\n",
    "1. Optimization Phase: For a given $\\tilde \\gamma$ we solve the problem, using some sort of optimization algorithm (IPOPT in our case),  \n",
    "\n",
    "\\begin{equation}\n",
    "      \\left\\{ \\int_0^\\infty \\exp(-\\delta t) \\left[-P^e  \\left (\\kappa\\sum_{i=1}^I Z^i_t- \\sum_{i=1}^I \\dot X^i_t \\right)+  P^a_t  \\sum_i \\theta^i Z^i_t-\\frac \\zeta 2 \\left (\\sum_i U_t^i + V_t^i \\right)^2 \\right ] dt\\right\\} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation} \\label{eq:z}\n",
    "\\dot Z_t^i = U_t^i - V_t^i . \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation} \\label{eq:x}\n",
    "{\\dot X}_t^i  = - \\tilde \\gamma^i U^i_t - \\alpha \\left[ X_t^i - \\tilde \\gamma^i  \\left( {{\\bar z}^i - Z_t^i }  \\right) \\right] \n",
    "\\end{equation}\n",
    "\n",
    "$$\n",
    "X_0^i = \\tilde \\gamma^i * C\n",
    "$$\n",
    "\n",
    "    where $C$ is some constant. \n",
    "\n",
    "2. MC phase: The algorithm for this part is the standard Metropolis-Hastings Algorirthm. The only thing that is a bit troublesome to deal with is the formulation of our likelihood which is $g$. \n",
    "\n",
    "    1. We are given $\\gamma^*$ via the MHMC algorithm. \n",
    "    2. Use $U_t^i$ and $V_t^i$ to evaluate the objective function under $\\gamma^*$. \n",
    "    3. Form the Likelihood $g$\n",
    "\n",
    "\\begin{equation}\\label{min_solution}\n",
    "g^* = \\exp\\left[ - {\\frac 1 \\xi } \\left\\{ \\int_0^\\infty \\exp(-\\delta t) \\left[-P^e  \\left (\\kappa\\sum_{i=1}^I Z^i_t- \\sum_{i=1}^I \\dot X^i_t \\right)+  P^a_t  \\sum_i \\theta^i Z^i_t-\\frac \\zeta 2 \\left (\\sum_i U_t^i + V_t^i \\right)^2 \\right ] dt\\right\\} \\right]\n",
    "\\end{equation} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Import Required Packages\n",
    "# ========================\n",
    "import os, sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import casadi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MCMC (HMC) sampling routines\n",
    "sys.path.append(os.path.abspath(\"mcmc\"))\n",
    "from mcmc_sampling import create_hmc_sampler\n",
    "\n",
    "# Data Hanlder (.data_handlers.load_site_data)\n",
    "from data_handlers import load_site_data\n",
    "\n",
    "# Local Debugging flag; remove when all tested\n",
    "_DEBUG = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17512abc",
   "metadata": {},
   "source": [
    "## Define a log density function suitable for MCMC sampling\n",
    "    Note that the log-density is the logarithm of the target density discarding any normalization factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518ca24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_density_function(gamma_val,\n",
    "                         gamma_vals_mean,\n",
    "                         theta_vals,\n",
    "                         N,\n",
    "                         site_precisions,\n",
    "                         alpha,\n",
    "                         # sol,\n",
    "                         sol_val_X,\n",
    "                         sol_val_Ua,\n",
    "                         sol_val_Up,\n",
    "                         zbar_2017,\n",
    "                         forestArea_2017_ha,\n",
    "                         norm_fac,\n",
    "                         alpha_p_Adym,\n",
    "                         Bdym,\n",
    "                         leng,\n",
    "                         T,\n",
    "                         ds_vect,\n",
    "                         zeta,\n",
    "                         xi,\n",
    "                         kappa,\n",
    "                         pa,\n",
    "                         pf,\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Define a function to evaluate log-density of the objective/posterior distribution\n",
    "    Some of the input parameters are updated at each cycle of the outer loop (optimization loop),\n",
    "    and it becomes then easier/cheaper to udpate the function stamp and keep it separate here\n",
    "    \"\"\"\n",
    "    \n",
    "    ds_vect    = np.asarray(ds_vect).flatten()\n",
    "    gamma_val  = np.asarray(gamma_val).flatten()\n",
    "    gamma_size = gamma_val.size\n",
    "    x0_vals    = gamma_val.T.dot(forestArea_2017_ha) / norm_fac\n",
    "    X_zero     = np.sum(x0_vals) * np.ones(leng)\n",
    "    \n",
    "    \n",
    "    # shifted_X = zbar_2017 - sol.value(X)[0:gamma_size, :-1]\n",
    "    shifted_X  = sol_val_X[0: gamma_size, :-1].copy()\n",
    "    for j in range(N): \n",
    "        shifted_X[:, j]  = zbar_2017 - shifted_X[:, j]\n",
    "    omega      = np.dot(gamma_val, alpha * shifted_X - sol_val_Up)\n",
    "    \n",
    "    X_dym      = np.zeros(T+1)\n",
    "    X_dym[0]   = np.sum(x0_vals)\n",
    "    X_dym[1: ] = alpha_p_Adym * X_zero  + np.dot(Bdym, omega.T)\n",
    "\n",
    "    z_shifted_X = sol_val_X[0: gamma_size, :].copy()\n",
    "    scl = pa * theta_vals - pf * kappa\n",
    "    for j in range(N+1):\n",
    "        z_shifted_X [:, j] *= scl\n",
    "    \n",
    "    term_1 = - np.sum(ds_vect[0: T] * sol_val_Ua) * zeta / 2 \n",
    "    term_2 =   np.sum(ds_vect[0: T] * (X_dym[1: ] - X_dym[0: -1])) * pf\n",
    "    term_3 =   np.sum(ds_vect * np.sum(z_shifted_X, axis=0))\n",
    "\n",
    "    obj_val = term_1 + term_2 + term_3\n",
    "    \n",
    "    gamma_val_dev   = gamma_val - gamma_vals_mean\n",
    "    norm_log_prob   =   - 0.5 * np.dot(gamma_val_dev,\n",
    "                                       site_precisions.dot(gamma_val_dev)\n",
    "                                       )\n",
    "    log_density_val = -1.0  / xi * obj_val + norm_log_prob\n",
    "    \n",
    "    log_density_val = float(log_density_val)\n",
    "    \n",
    "    if _DEBUG:\n",
    "        print(\"Term 1: \", term_1)\n",
    "        print(\"Term 2: \", term_2)\n",
    "        print(\"Term 3: \", term_3)\n",
    "        print(\"obj_val: \", obj_val)\n",
    "        print(\"norm_log_prob\", norm_log_prob)\n",
    "        print(\"log_density_val\", log_density_val)\n",
    "    \n",
    "    return log_density_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356eca0b",
   "metadata": {},
   "source": [
    "### Unified main interface to tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a21fbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    # Configurations/Settings\n",
    "    site_num          = 100,  # Number of sites(10, 25, 100, 1000)\n",
    "    norm_fac          = 1e9,\n",
    "    delta_t           = 0.02,\n",
    "    alpha             = 0.045007414,\n",
    "    kappa             = 2.094215255,\n",
    "    pf                = 20.76,\n",
    "    pa                = 44.75,\n",
    "    xi                = 0.01,\n",
    "    zeta              = 1.66e-4*1e9,  # zeta := 1.66e-4*norm_fac  #\n",
    "    #\n",
    "    max_iter          = 200,\n",
    "    tol               = 0.01,\n",
    "    T                 = 200,\n",
    "    N                 = 200,\n",
    "    #\n",
    "    sample_size       = 1000,    # simulations before convergence (to evaluate the mean)\n",
    "    mode_as_solution  = False,   # If true, use the mode (point of high probability) as solution for gamma\n",
    "    final_sample_size = 100_00,  # number of samples to collect after convergence\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Main function; putting things together\n",
    "\n",
    "    :param float tol: convergence tolerance\n",
    "    :param T:\n",
    "    :param N:\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Load sites' data\n",
    "    (\n",
    "        zbar_2017,\n",
    "        gamma, \n",
    "        gammaSD,\n",
    "        z_2017, \n",
    "        forestArea_2017_ha, \n",
    "        theta,\n",
    "        thetaSD,\n",
    "    ) = load_site_data(site_num, norm_fac=norm_fac, )\n",
    "\n",
    "\n",
    "    # Evaluate Gamma values ()\n",
    "    gamma_1_vals  = gamma -  gammaSD\n",
    "    gamma_2_vals  = gamma +  gammaSD\n",
    "    gamma_size    = gamma.size\n",
    "\n",
    "    # Evaluate mean and covariances from site data\n",
    "    site_stdev       = gammaSD\n",
    "    site_covariances = np.diag(np.power(site_stdev, 2))\n",
    "    site_precisions  = np.linalg.inv(site_covariances)\n",
    "    site_mean        = gamma_1_vals/2 + gamma_2_vals/2\n",
    "\n",
    "    # Retrieve z data for selected site(s)\n",
    "    site_z_vals  = z_2017\n",
    "\n",
    "    # Initialize Gamma Values\n",
    "    gamma_vals      = gamma.copy()\n",
    "    gamma_vals_mean = gamma.copy()\n",
    "    gamma_vals_old  = gamma.copy()\n",
    "\n",
    "    # Theta Values\n",
    "    theta_vals  = theta\n",
    "\n",
    "    # Householder to track sampled gamma values\n",
    "    # gamma_vals_tracker       = np.empty((gamma_vals.size, sample_size+1))\n",
    "    # gamma_vals_tracker[:, 0] = gamma_vals.copy()\n",
    "    gamma_vals_tracker = [gamma_vals.copy()]\n",
    "\n",
    "    # Collected Ensembles over all iterations; dictionary indexed by iteration number\n",
    "    collected_ensembles = {}\n",
    "\n",
    "    # Track error over iterations\n",
    "    error_tracker = []\n",
    "\n",
    "    # Update this parameter (leng) once figured out where it is coming from\n",
    "    leng = 200\n",
    "    arr  = np.cumsum(\n",
    "             np.triu(\n",
    "             np.ones((leng, leng))\n",
    "         ),\n",
    "         axis=1,\n",
    "    ).T\n",
    "    Bdym         = (1-alpha) ** (arr-1)\n",
    "    Bdym[Bdym>1] = 0.0\n",
    "    Adym         = np.arange(1, leng+1)\n",
    "    alpha_p_Adym = np.power(1-alpha, Adym)\n",
    "\n",
    "    # Initialize Blocks of the A matrix those won't change\n",
    "    A  = np.zeros((gamma_size+2, gamma_size+2))\n",
    "    Ax = np.zeros(gamma_size+2)\n",
    "\n",
    "    # Construct Matrix B\n",
    "    B = np.eye(N=gamma_size+2, M=gamma_size, k=0)\n",
    "    B = casadi.sparsify(B)\n",
    "\n",
    "    # Construct Matrxi D constant blocks\n",
    "    D  = np.zeros((gamma_size+2, gamma_size))\n",
    "\n",
    "    # time step!\n",
    "    dt = T / N\n",
    "\n",
    "    # Other placeholders!\n",
    "    ds_vect = np.exp(- delta_t * np.arange(N+1) * dt)\n",
    "    ds_vect = np.reshape(ds_vect, (ds_vect.size, 1))\n",
    "\n",
    "    # Results dictionary\n",
    "    results = dict(\n",
    "        gamma_size=gamma_size,\n",
    "        tol=tol,\n",
    "        T=T,\n",
    "        N=N,\n",
    "        norm_fac=norm_fac,\n",
    "        delta_t=delta_t,\n",
    "        alpha=alpha,\n",
    "        kappa=kappa,\n",
    "        pf=pf,\n",
    "        pa=pa,\n",
    "        xi=xi,\n",
    "        zeta=zeta,\n",
    "        sample_size=sample_size,\n",
    "        final_sample_size=final_sample_size,\n",
    "        mode_as_solution=mode_as_solution,\n",
    "    )\n",
    "\n",
    "    # Initialize error & iteration counter\n",
    "    error = np.infty\n",
    "    cntr = 0\n",
    "\n",
    "    # Loop until convergence\n",
    "    while cntr < max_iter and error > tol:\n",
    "\n",
    "        # Update x0\n",
    "        x0_vals = gamma_vals * forestArea_2017_ha / norm_fac\n",
    "\n",
    "        # Construct Matrix A from new gamma_vals\n",
    "        A[: -2, :]        = 0.0\n",
    "        Ax[0: gamma_size] = - alpha * gamma_vals[0: gamma_size]\n",
    "        Ax[-1]            = alpha * np.sum(gamma_vals * zbar_2017)\n",
    "        Ax[-2]            = - alpha\n",
    "        A[-2, :]          = Ax\n",
    "        A[-1, :]          = 0.0\n",
    "        A = casadi.sparsify(A)\n",
    "\n",
    "        # Construct Matrix D from new gamma_vals\n",
    "        D[:, :]  = 0.0\n",
    "        D[-2, :] = -gamma_vals\n",
    "        D = casadi.sparsify(D)\n",
    "        \n",
    "        # Define the right hand side (symbolic here) as a function of gamma\n",
    "        gamma = casadi.MX.sym('gamma' , gamma_size+2)\n",
    "        up    = casadi.MX.sym('up', gamma_size)\n",
    "        um    = casadi.MX.sym('um', gamma_size)\n",
    "\n",
    "        rhs = (A @ gamma + B @ (up-um) + D @ up) * dt + gamma\n",
    "        f = casadi.Function('f', [gamma, um, up], [rhs])\n",
    "        \n",
    "\n",
    "        ## Define an optimizer and initialize it, and set constraints\n",
    "        opti = casadi.Opti()\n",
    "\n",
    "        # Decision variables for states\n",
    "        X = opti.variable(gamma_size+2, N+1)\n",
    "\n",
    "        # Aliases for states\n",
    "        Up = opti.variable(gamma_size, N)\n",
    "        Um = opti.variable(gamma_size, N)\n",
    "        Ua = opti.variable(1, N)\n",
    "\n",
    "        # 1.2: Parameter for initial state\n",
    "        ic = opti.parameter(gamma_size+2)\n",
    "\n",
    "        # Gap-closing shooting constraints\n",
    "        for k in range(N):\n",
    "            opti.subject_to(X[:, k+1] == f(X[:, k], Um[:, k], Up[:, k]))\n",
    "\n",
    "        # Initial and terminal constraints\n",
    "        opti.subject_to(X[:, 0] == ic)\n",
    "        opti.subject_to(opti.bounded(0,\n",
    "                                     X[0: gamma_size, :],\n",
    "                                     zbar_2017[0: gamma_size]\n",
    "                                     )\n",
    "                        )\n",
    "\n",
    "        # Objective: regularization of controls\n",
    "        for k in range(gamma_size):\n",
    "            opti.subject_to(opti.bounded(0, Um[k,:], casadi.inf))\n",
    "            opti.subject_to(opti.bounded(0, Up[k,:], casadi.inf))\n",
    "\n",
    "        opti.subject_to(Ua == casadi.sum1(Up+Um)**2)\n",
    "\n",
    "        # Set teh optimization problem\n",
    "        term1 =   casadi.sum2(ds_vect[0: N, :].T * Ua * zeta / 2) \n",
    "        term2 = - casadi.sum2(ds_vect[0: N, :].T * (pf * (X[-2, 1: ] - X[-2, 0 :-1])))\n",
    "        term3 = - casadi.sum2(ds_vect.T * casadi.sum1( (pa * theta_vals - pf * kappa ) * X[0: gamma_size, :] ))\n",
    "        \n",
    "        opti.minimize(term1 + term2 + term3)\n",
    "\n",
    "        # Solve optimization problem\n",
    "        options               = dict()\n",
    "        options[\"print_time\"] = True\n",
    "        options[\"expand\"]     = True\n",
    "        options[\"ipopt\"]      = {'print_level':                      1,\n",
    "                                 'fast_step_computation':            'yes',\n",
    "                                 'mu_allow_fast_monotone_decrease':  'yes',\n",
    "                                 'warm_start_init_point':            'yes',\n",
    "                                 }\n",
    "        opti.solver('ipopt', options)\n",
    "        \n",
    "        opti.set_value(ic,\n",
    "                       casadi.vertcat(site_z_vals,\n",
    "                                      np.sum(x0_vals),\n",
    "                                      1),\n",
    "                       )\n",
    "        \n",
    "        if _DEBUG:\n",
    "            print(\"ic: \", ic)\n",
    "            print(\"site_z_vals: \", site_z_vals)\n",
    "            print(\"x0_vals: \", x0_vals)\n",
    "            print(\"casadi.vertcat(site_z_vals,np.sum(x0_vals),1): \", casadi.vertcat(site_z_vals,np.sum(x0_vals),1))\n",
    "        \n",
    "        # TODO: Discuss with Daniel how this is taking too long, not the sampling!\n",
    "        print(\"solving the Outer Optimization problem\")\n",
    "        start_time = time.time()\n",
    "        sol = opti.solve()\n",
    "        print(f\"Done; time taken {time.time()-start_time} seconds...\")\n",
    "\n",
    "        if _DEBUG:\n",
    "            print(\"sol.value(X)\", sol.value(X))\n",
    "            print(\"sol.value(Ua)\", sol.value(Ua))\n",
    "            print(\"sol.value(Up)\", sol.value(Up))\n",
    "            print(\"sol.value(Um)\", sol.value(Um))\n",
    "        \n",
    "        \n",
    "        # Extract information from the solver\n",
    "        N          = X.shape[1]-1\n",
    "        sol_val_X  = sol.value(X)\n",
    "        sol_val_Up = sol.value(Up)\n",
    "        sol_val_Ua = sol.value(Ua)\n",
    "        \n",
    "        ## Start Sampling\n",
    "        # Update signature of log density evaluator\n",
    "        log_density = lambda gamma_val: log_density_function(gamma_val=gamma_val,\n",
    "                                                             gamma_vals_mean=gamma_vals_mean,\n",
    "                                                             theta_vals=theta_vals,\n",
    "                                                             site_precisions=site_precisions,\n",
    "                                                             alpha=alpha,\n",
    "                                                             N=N, \n",
    "                                                             # sol=sol,\n",
    "                                                             sol_val_X=sol_val_X,\n",
    "                                                             sol_val_Ua=sol_val_Ua,\n",
    "                                                             sol_val_Up=sol_val_Up,\n",
    "                                                             zbar_2017=zbar_2017,\n",
    "                                                             forestArea_2017_ha=forestArea_2017_ha,\n",
    "                                                             norm_fac=norm_fac,\n",
    "                                                             alpha_p_Adym=alpha_p_Adym,\n",
    "                                                             Bdym=Bdym,\n",
    "                                                             leng=leng,\n",
    "                                                             T=T,\n",
    "                                                             ds_vect=ds_vect,\n",
    "                                                             zeta=zeta,\n",
    "                                                             xi=xi,\n",
    "                                                             kappa=kappa,\n",
    "                                                             pa=pa,\n",
    "                                                             pf=pf,\n",
    "                                                             )\n",
    "\n",
    "        # Create MCMC sampler & sample, then calculate diagnostics\n",
    "        sampler = create_hmc_sampler(\n",
    "            size=gamma_size,\n",
    "            log_density=log_density,\n",
    "            #\n",
    "            burn_in=100,\n",
    "            mix_in=2,\n",
    "            symplectic_integrator='verlet',\n",
    "            symplectic_integrator_stepsize=1e-1,\n",
    "            symplectic_integrator_num_steps=3,\n",
    "            mass_matrix=1e+1,\n",
    "            constraint_test=lambda x: True if np.all(x>=0) else False,\n",
    "        )\n",
    "        gamma_post_samples = sampler.sample(\n",
    "            sample_size=sample_size,\n",
    "            initial_state=gamma_vals,\n",
    "            verbose=True,\n",
    "        )\n",
    "        gamma_post_samples = np.asarray(gamma_post_samples)\n",
    "\n",
    "        # Update ensemble/tracker\n",
    "        collected_ensembles.update({cntr: gamma_post_samples.copy()})\n",
    "\n",
    "        # Update gamma value\n",
    "        weight     = 0.25  # <-- Not sure how this linear combination weighting helps!\n",
    "        if mode_as_solution:\n",
    "            raise NotImplementedError(\"We will consider this in the future; trace sampled points and keep track of objective values to pick one with highest prob. \")\n",
    "            \n",
    "        else:\n",
    "            gamma_vals = weight * np.mean(gamma_post_samples, axis=0 ) + (1-weight) * gamma_vals_old\n",
    "        gamma_vals_tracker.append(gamma_vals.copy())\n",
    "\n",
    "        # Evaluate error for convergence check\n",
    "        error = np.max(np.abs(gamma_vals_old-gamma_vals) / gamma_vals_old)\n",
    "        error_tracker.append(error)\n",
    "        print(f\"Iteration [{cntr+1:4d}]: Error = {error}\")\n",
    "\n",
    "        # Exchange gamma values (for future weighting/update & error evaluation)\n",
    "        gamma_vals_old = gamma_vals\n",
    "\n",
    "        # Increase the counter\n",
    "        cntr += 1\n",
    "\n",
    "        results.update({'cntr': cntr,\n",
    "                        'error_tracker':np.asarray(error_tracker),\n",
    "                        'gamma_vals_tracker': np.asarray(gamma_vals_tracker),\n",
    "                        'collected_ensembles':collected_ensembles,\n",
    "                        })\n",
    "        pickle.dump(results, open('results.pcl', 'wb'))\n",
    "        \n",
    "        # Extensive plotting for monitoring; not needed really!\n",
    "        if False:\n",
    "            plt.plot(gamma_vals_tracker[-2], label=r'Old $\\gamma$')\n",
    "            plt.plot(gamma_vals_tracker[-1], label=r'New $\\gamma$')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            for j in range(gamma_size):\n",
    "                plt.hist(gamma_post_samples[:, j], bins=50)\n",
    "                plt.title(f\"Iteration {cntr}; Site {j+1}\")\n",
    "                plt.show()\n",
    "    \n",
    "    print(\"Terminated. Sampling the final distribution\")\n",
    "    # Sample (densly) the final distribution\n",
    "    final_sample = sampler.sample(\n",
    "        sample_size=final_sample_size,\n",
    "        initial_state=gamma_vals,\n",
    "        verbose=True,\n",
    "    )\n",
    "    final_sample = np.asarray(final_sample)\n",
    "    results.update({'final_sample': final_sample})\n",
    "    pickle.dump(results, open('results.pcl', 'wb'))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6bc74",
   "metadata": {},
   "source": [
    "## Start Running the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2566dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the main interface `main` with default settings\n",
    "results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c79f95",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Error Results\n",
    "plt.plot(results['error_tracker'])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Gamma Estimate Update\n",
    "for j in range(results['gamma_size']):\n",
    "    plt.plot(results['gamma_vals_tracker'][:, j], label=r\"$\\gamma_{%d}$\"%(j+1))\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), ncol=2, loc=\"center left\", borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbf2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms\n",
    "for itr in results['collected_ensembles'].keys():\n",
    "    for j in range(results['gamma_size']):\n",
    "        plt.hist(results['collected_ensembles'][itr][:, j], bins=100)\n",
    "        plt.title(f\"Iteration {itr+1}; Site {j+1}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram of the final sample\n",
    "for j in range(results['gamma_size']):\n",
    "    plt.hist(results['final_sample'][:, j], bins=100)\n",
    "    plt.title(f\"Final Sample; Site {j+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3be0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
